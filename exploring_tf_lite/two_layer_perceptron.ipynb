{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from math import log2, ceil, floor\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(HOME_DIR, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_dict(t):\n",
    "    f = t.flatten().tolist()\n",
    "    s = list(t.shape)\n",
    "    c = [1]\n",
    "\n",
    "    for e in s[-1:0:-1]:\n",
    "        c.append(c[-1] * e)\n",
    "    \n",
    "    c.reverse()\n",
    "\n",
    "    return OrderedDict([(\"f\", f), (\"s\", s), (\"c\", c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_nearest(x, scale, zero, qtype):\n",
    "    if qtype not in {np.int8, np.uint8}:\n",
    "        raise Exception(\"Only quantization to int8 or uint8 is supported\")\n",
    "    \n",
    "    (min, max) = (-128, 127) if qtype == np.int8 else (0, 255)\n",
    "\n",
    "    return np.clip(np.rint(x / scale) + zero, min, max).astype(qtype)\n",
    "\n",
    "def fc_and_requantize(input_tensor, weights, bias, q_i, q_w, q_o):\n",
    "    \n",
    "    if input_tensor.dtype != np.int8:\n",
    "        raise Exception(\"Input must be of type int8\")\n",
    "    \n",
    "    if weights.dtype != np.int8:\n",
    "        raise Exception(\"Weights must be of type int8\")\n",
    "    \n",
    "    if bias.dtype != np.int32:\n",
    "        raise Exception(\"Input and weights must be of type int32\")\n",
    "    \n",
    "    (s_i, z_i), (s_w, z_w), (s_o, z_o) = q_i, q_w, q_o\n",
    "    \n",
    "    if z_w != 0:\n",
    "        raise Exception(\"Expected zero point of weights to be 0\")\n",
    "\n",
    "    s = s_i * s_w / s_o\n",
    "\n",
    "    # 1) shift input tensor\n",
    "    input_tensor_32 = input_tensor.astype(np.int32) - z_i\n",
    "    weights_32 = weights.astype(np.int32)\n",
    "\n",
    "    # 2) compute the bmm\n",
    "    bmm = np.matmul(input_tensor_32, weights_32.transpose()) + bias\n",
    "\n",
    "    # 3) requantize\n",
    "    rq = np.rint(s * bmm) + z_o\n",
    "\n",
    "    # 4) saturating cast\n",
    "    output = np.clip(rq, -128, 127).astype(np.int8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255.0, x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(os.path.join(MODEL_DIR, \"two_layer_perceptron_frozen.tflite\"), experimental_preserve_all_tensors=True)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "print(input_details)\n",
    "print(input_details[\"dtype\"])\n",
    "\n",
    "print(output_details)\n",
    "print(output_details[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(interpreter.get_tensor_details()):\n",
    "    print(i, \": \", t[\"name\"], sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter._get_ops_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1_idx = 7\n",
    "weight_1_idx = 5\n",
    "bias_1_idx = 4\n",
    "output_1_idx = 8\n",
    "\n",
    "w_1 = interpreter.get_tensor(weight_1_idx)\n",
    "b_1 = interpreter.get_tensor(bias_1_idx)\n",
    "q_1_i = interpreter.get_tensor_details()[input_1_idx][\"quantization\"]\n",
    "q_1_w = interpreter.get_tensor_details()[weight_1_idx][\"quantization\"]\n",
    "q_1_o = interpreter.get_tensor_details()[output_1_idx][\"quantization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2_idx = 8\n",
    "weight_2_idx = 3\n",
    "bias_2_idx = 2\n",
    "output_2_idx = 9\n",
    "\n",
    "w_2 = interpreter.get_tensor(weight_2_idx)\n",
    "b_2 = interpreter.get_tensor(bias_2_idx)\n",
    "q_2_i = interpreter.get_tensor_details()[input_2_idx][\"quantization\"]\n",
    "q_2_w = interpreter.get_tensor_details()[weight_2_idx][\"quantization\"]\n",
    "q_2_o = interpreter.get_tensor_details()[output_2_idx][\"quantization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_zero_point = q_1_o[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_model(input_tensor):\n",
    "\n",
    "    # 1) shift input tensor by -128 to sitch from input type (uint8) to TF Lite internal type (int8) \n",
    "    shifted_input = input_tensor.astype(np.int32)\n",
    "    shifted_input = shifted_input - 128\n",
    "    shifted_input = shifted_input.astype(np.int8)\n",
    "\n",
    "    # 2) flatten input\n",
    "    flattened_input = shifted_input.reshape(interpreter.get_tensor(1)) # [-1, 784]\n",
    "    \n",
    "    # 3) first fully-connected layer\n",
    "    fc1 = fc_and_requantize(flattened_input, w_1, b_1, q_1_i, q_1_w, q_1_o)\n",
    "\n",
    "    # 4) relu\n",
    "    relu1 = np.maximum(fc1, relu_zero_point)\n",
    "\n",
    "    # 5) second fully-connected layer\n",
    "    fc2 = fc_and_requantize(relu1, w_2, b_2, q_2_i, q_2_w, q_2_o)\n",
    "\n",
    "    # 4) undo the shift to switch from TF Lite internal type (int8) to output type (uint8)\n",
    "    output = fc2.astype(np.int32)\n",
    "    output = output + 128\n",
    "    output = output.astype(np.uint8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(input_tensor, verbose):\n",
    "\n",
    "    # Need to quantize the inputs outside the model!\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    input_tensor = quantize_nearest(input_tensor, input_scale, input_zero_point, np.uint8)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "    # Run the TF Lite model\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_tensor)\n",
    "    interpreter.invoke()\n",
    "    tflite_output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    # Run the manual model\n",
    "    manual_output = manual_model(input_tensor)[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Manual model output:\\t{}\".format(manual_output))\n",
    "    \n",
    "    print( \"Models match\" if (manual_output == tflite_output).all() else \"Mismatch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_IMAGE = 150\n",
    "\n",
    "compare_models(x_test[CHOSEN_IMAGE], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manual_model(input_tensor):\n",
    "\n",
    "    # Need to quantize the inputs outside the model!\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    input_tensor = quantize_nearest(input_tensor, input_scale, input_zero_point, np.uint8)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "    \n",
    "    return manual_model(input_tensor)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randrange\n",
    "# [randrange(0, len(x_test)) for _ in range(10)]\n",
    "\n",
    "INDICES = [6393, 1894, 5978, 6120, 817, 3843, 7626, 9272, 498, 4622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in INDICES:\n",
    "    compare_models(x_test[i], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = zip(*[(tensor_to_dict(x_test[i]), tensor_to_dict(run_manual_model(x_test[i]))) for i in INDICES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(inputs, open(\"10_test_inputs.json\", \"w\"))\n",
    "json.dump(outputs, open(\"10_test_outputs.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
