{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import log2, floor\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(HOME_DIR, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_nearest(x, scale, zero, qtype):\n",
    "    if qtype not in {np.int8, np.uint8}:\n",
    "        raise Exception(\"Only quantization to int8 or uint8 is supported\")\n",
    "    \n",
    "    (min, max) = (-128, 127) if qtype == np.int8 else (0, 255)\n",
    "\n",
    "    return np.clip(np.rint(x / scale) + zero, min, max).astype(qtype)\n",
    "\n",
    "def fc_and_requantize(input_tensor, weights, bias, q_i, q_w, q_o):\n",
    "    \n",
    "    if input_tensor.dtype != np.int8:\n",
    "        raise Exception(\"Input must be of type int8\")\n",
    "    \n",
    "    if weights.dtype != np.int8:\n",
    "        raise Exception(\"Weights must be of type int8\")\n",
    "    \n",
    "    if bias.dtype != np.int32:\n",
    "        raise Exception(\"Input and weights must be of type int32\")\n",
    "    \n",
    "    (s_i, z_i), (s_w, z_w), (s_o, z_o) = q_i, q_w, q_o\n",
    "    \n",
    "    if z_w != 0:\n",
    "        raise Exception(\"Expected zero point of weights to be 0\")\n",
    "\n",
    "    s = s_i * s_w / s_o\n",
    "\n",
    "    # 1) shift input tensor\n",
    "    input_tensor_32 = input_tensor.astype(np.int32) - z_i\n",
    "    weights_32 = weights.astype(np.int32)\n",
    "\n",
    "    # 2) compute the bmm\n",
    "    bmm = np.matmul(input_tensor_32, weights_32.transpose()) + bias\n",
    "\n",
    "    # 3) requantize\n",
    "    rq = np.rint(s * bmm) + z_o\n",
    "\n",
    "    # 4) saturating cast\n",
    "    output = np.clip(rq, -128, 127).astype(np.int8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255.0, x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model\n",
    "\n",
    "(not ready; go to \"Simple model\" below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(os.path.join(MODEL_DIR, \"mnist_model_quant.tflite\"))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tensors = [None] * 11\n",
    "\n",
    "for i in range(11):\n",
    "    try:\n",
    "        initial_tensors[i] = interpreter.get_tensor(i).copy()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'serving_default_flatten_3_input:0', 'index': 0, 'shape': array([ 1, 28, 28], dtype=int32), 'shape_signature': array([-1, 28, 28], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003921568859368563, 0), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "<class 'numpy.uint8'>\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 10, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.2266918420791626, 143), 'quantization_parameters': {'scales': array([0.22669184], dtype=float32), 'zero_points': array([143], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "<class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "print(input_details)\n",
    "print(input_details[\"dtype\"])\n",
    "\n",
    "print(output_details)\n",
    "print(output_details[\"dtype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_image = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131 128 120 123 152 117 191 125 130 109]\n",
      "6 (correct: 6)\n"
     ]
    }
   ],
   "source": [
    "test_image = x_test[chosen_image]\n",
    "\n",
    "# Need to quantize the inputs outside the model!\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "# quantisation transformation as float32 first\n",
    "test_image = quantize_nearest(test_image, input_scale, input_zero_point, np.uint8)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "output_prediction = output.argmax()\n",
    "\n",
    "print(output)\n",
    "print(\"{} (correct: {})\".format(y_test[chosen_image], output_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: to perform a saturating cast, one must use np.clip. Otherwise problematic things happen - for instance, from f32 to u8, it seems first the floor is applied followed by % 256 (which is not what we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\n",
      "[214]\n",
      "[0]\n",
      "[166]\n",
      "[255]\n"
     ]
    }
   ],
   "source": [
    "arr_200 = np.array([200], dtype=np.float32)\n",
    "print(arr_200.astype(np.uint8))\n",
    "\n",
    "arr_m42 = np.array([-42], dtype=np.float32)\n",
    "print(arr_m42.astype(np.uint8))\n",
    "print(np.clip(arr_m42, 0, 255).astype(np.uint8))\n",
    "\n",
    "arr_422 = np.array([422], dtype=np.float32)\n",
    "print(arr_422.astype(np.uint8))\n",
    "print(np.clip(arr_422, 0, 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The tensors in the interpreter (cf. next cell) should be interpreted as follows:\n",
    "- 0: `serving_default_flatten_3_input:0`: it simply holds the (already quantised) input tensor (u8, initialised to 0)\n",
    "- 1: `sequential_6/flatten_3/Const`: it stores, as a constant, the shape that the input should be flattened to by the Reshape node (cf. 7), to which it is an input (i32, does not change)\n",
    "- 2: `sequential_6/dense_7/BiasAdd/ReadVariableOp`: it holds the bias for the second FC layer (identified by `dense_7`), and it consists of 10 `i32`s\n",
    "- 3: `sequential_6/dense_7/MatMul`: this is the vec-by-matrix multiplication for the second FC layer. It holds the matrix coefficients as with entries in `i8`. The vector's has entries in ???. The two are multiplied together in `i32` precision to avoid overflows.\n",
    "- 4: `sequential_6/dense_6/BiasAdd/ReadVariableOp`: it holds the bias for the first FC layer  (cf. 2)\n",
    "- 5: `sequential_6/dense_6/MatMul`: this is the vec-by-matrix multiplication for the first FC layer (cf. 3)\n",
    "- 6: `tfl.quantize`: this has the exact same quantisation scale as the input node, but the zero point is -128 as opposed to 0. Also, I am unsure what it does, since input quantisation needs to be performed externally by the user... (it changes during inference!)\n",
    "- 7: `sequential_6/flatten_3/Reshape`: it flattens the 28 x 28 image into a flat 784-element vector (no value)\n",
    "- 8: `sequential_6/dense_6/MatMul;sequential_6/activation_3/Relu;sequential_6/dense_6/BiasAdd`: this performs BMM and ReLU (no value)\n",
    "- 9: `StatefulPartitionedCall:01`: ??? (i8, initial value: 0)\n",
    "- 10: `StatefulPartitionedCall:0`: holds the actual output (u8, initial value: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tensors = [None] * 11\n",
    "\n",
    "for i in range(11):\n",
    "    try:\n",
    "        final_tensors[i] = interpreter.get_tensor(i).copy()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias2\u001b[39m\u001b[38;5;124m\"\u001b[39m: interpreter\u001b[38;5;241m.\u001b[39mget_tensor(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcopy(),\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmat2\u001b[39m\u001b[38;5;124m\"\u001b[39m: interpreter\u001b[38;5;241m.\u001b[39mget_tensor(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcopy(),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias1\u001b[39m\u001b[38;5;124m\"\u001b[39m: interpreter\u001b[38;5;241m.\u001b[39mget_tensor(\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mcopy(),\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmat1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy(),\n\u001b[1;32m      6\u001b[0m }\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/lite/python/interpreter.py:876\u001b[0m, in \u001b[0;36mInterpreter.get_tensor\u001b[0;34m(self, tensor_index, subgraph_index)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, subgraph_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    862\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the value of the output tensor (get a copy).\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m  If you wish to avoid the copy, use `tensor()`. This function cannot be used\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m    a numpy array.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraph_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"bias2\": interpreter.get_tensor(2).copy(),\n",
    "    \"mat2\": interpreter.get_tensor(3).copy(),\n",
    "    \"bias1\": interpreter.get_tensor(4).copy(),\n",
    "    \"mat1\": interpreter.get_tensor(5).copy(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m s_i1 \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_tensor_details()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m s_w1 \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_tensor_details()[\u001b[38;5;241m5\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m s_o1 \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m s_i1, s_w1, s_o1\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "s_i1 = interpreter.get_tensor_details()[0][\"quantization\"][0]\n",
    "s_w1 = interpreter.get_tensor_details()[5][\"quantization\"][0]\n",
    "s_o1 = interpreter.get_tensor_details()[8][\"quantization\"][0]\n",
    "s_i1, s_w1, s_o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.038711175322532654, 0.007592691574245691, 0.2266918420791626)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_i2 = interpreter.get_tensor_details()[8][\"quantization\"][0]\n",
    "s_w2 = interpreter.get_tensor_details()[3][\"quantization\"][0]\n",
    "s_o2 = interpreter.get_tensor_details()[9][\"quantization\"][0]\n",
    "s_i2, s_w2, s_o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = test_image\n",
    "flattened_input = input_tensor.flatten()\n",
    "# TODO I think the next two lines do the same as the third on its own\n",
    "precision_input = flattened_input.astype(np.int32)\n",
    "quantised_input = precision_input - 128\n",
    "finalised_input = quantised_input.astype(np.int8)\n",
    "\n",
    "fc1 = fc_and_requantize(finalised_input, params[\"mat1\"], params[\"bias1\"], s_i1, s_w1, s_o1)\n",
    "\n",
    "# Applying ReLU to i8 input\n",
    "relu = fc1.clip(0, 127)\n",
    "\n",
    "fc2 = fc_and_requantize(relu, params[\"mat2\"], params[\"bias2\"], s_i2, s_w2, s_o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -61,  -28, -102, -128,   59,  -37,  -70,  -31,  -63,  -56],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = (np.matmul(finalised_input.astype(np.int32), params[\"mat1\"].astype(np.int32).transpose()) + params[\"bias1\"]) * s_i1 * s_w1 / s_o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v.clip(-128, 127).astype(np.int8).clip(0, 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -72.16972182,  -64.82853816, -116.54355962, -113.76111877,\n",
       "         41.17908744,  -23.50034508, -141.97709171,  -48.27132951,\n",
       "        -50.38862957,    1.92151787])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.matmul(v2.astype(np.int32), params[\"mat2\"].astype(np.int32).transpose()) + params[\"bias2\"]) * s_i2 * s_w2 / s_o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -73,  -65, -116, -114,   41,  -24, -128,  -48,  -51,    2],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(9)\n",
    "fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, fz = interpreter.get_tensor_details()[9][\"quantization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2266918420791626, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs, fz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-307.02305707, -271.73285904, -496.70787151, -487.88532201,\n",
       "        195.86226493,  -90.87059411, -549.64316857, -196.74118821,\n",
       "       -209.97501248,   23.82254951])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2/fs + fz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-128, -128, -128, -128, -128, -128, -128, -128, -128, -128]],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(9) - interpreter.get_tensor(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(os.path.join(MODEL_DIR, \"simple_model_quant.tflite\"), experimental_preserve_all_tensors=True)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'serving_default_flatten_2_input:0', 'index': 0, 'shape': array([ 1, 28, 28], dtype=int32), 'shape_signature': array([-1, 28, 28], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003921568859368563, 0), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "<class 'numpy.uint8'>\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 7, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.1573459506034851, 175), 'quantization_parameters': {'scales': array([0.15734595], dtype=float32), 'zero_points': array([175], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "<class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "print(input_details)\n",
    "print(input_details[\"dtype\"])\n",
    "\n",
    "print(output_details)\n",
    "print(output_details[\"dtype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_image = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135 109 152 161 187 157 159 151 173 202]\n",
      "9 (correct: 9)\n"
     ]
    }
   ],
   "source": [
    "test_image = x_test[chosen_image]\n",
    "\n",
    "# Need to quantize the inputs outside the model!\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "input_tensor = quantize_nearest(test_image, input_scale, input_zero_point, np.uint8)\n",
    "input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "# Run the model\n",
    "interpreter.set_tensor(input_details[\"index\"], input_tensor)\n",
    "interpreter.invoke()\n",
    "tflite_output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "output_prediction = tflite_output.argmax()\n",
    "\n",
    "print(tflite_output)\n",
    "print(\"{} (correct: {})\".format(output_prediction, y_test[chosen_image]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_flatten_2_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 28, 28], dtype=int32),\n",
       "  'shape_signature': array([-1, 28, 28], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.003921568859368563, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/flatten_2/Const',\n",
       "  'index': 1,\n",
       "  'shape': array([2], dtype=int32),\n",
       "  'shape_signature': array([2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/dense_2/BiasAdd/ReadVariableOp',\n",
       "  'index': 2,\n",
       "  'shape': array([10], dtype=int32),\n",
       "  'shape_signature': array([10], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (4.8770318244351074e-05, 0),\n",
       "  'quantization_parameters': {'scales': array([4.877032e-05], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/dense_2/MatMul',\n",
       "  'index': 3,\n",
       "  'shape': array([ 10, 784], dtype=int32),\n",
       "  'shape_signature': array([ 10, 784], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.012436429969966412, 0),\n",
       "  'quantization_parameters': {'scales': array([0.01243643], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'tfl.quantize',\n",
       "  'index': 4,\n",
       "  'shape': array([ 1, 28, 28], dtype=int32),\n",
       "  'shape_signature': array([-1, 28, 28], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/flatten_2/Reshape',\n",
       "  'index': 5,\n",
       "  'shape': array([  1, 784], dtype=int32),\n",
       "  'shape_signature': array([ -1, 784], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'StatefulPartitionedCall:01',\n",
       "  'index': 6,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([-1, 10], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.1573459506034851, 47),\n",
       "  'quantization_parameters': {'scales': array([0.15734595], dtype=float32),\n",
       "   'zero_points': array([47], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 7,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([-1, 10], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.1573459506034851, 175),\n",
       "  'quantization_parameters': {'scales': array([0.15734595], dtype=float32),\n",
       "   'zero_points': array([175], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: serving_default_flatten_2_input:0\n",
      "1: sequential_3/flatten_2/Const\n",
      "2: sequential_3/dense_2/BiasAdd/ReadVariableOp\n",
      "3: sequential_3/dense_2/MatMul\n",
      "4: tfl.quantize\n",
      "5: sequential_3/flatten_2/Reshape\n",
      "6: StatefulPartitionedCall:01\n",
      "7: StatefulPartitionedCall:0\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(interpreter.get_tensor_details()):\n",
    "    print(i, \": \", t[\"name\"], sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'op_name': 'QUANTIZE',\n",
       "  'inputs': array([0], dtype=int32),\n",
       "  'outputs': array([4], dtype=int32)},\n",
       " {'index': 1,\n",
       "  'op_name': 'RESHAPE',\n",
       "  'inputs': array([4, 1], dtype=int32),\n",
       "  'outputs': array([5], dtype=int32)},\n",
       " {'index': 2,\n",
       "  'op_name': 'FULLY_CONNECTED',\n",
       "  'inputs': array([5, 3, 2], dtype=int32),\n",
       "  'outputs': array([6], dtype=int32)},\n",
       " {'index': 3,\n",
       "  'op_name': 'QUANTIZE',\n",
       "  'inputs': array([6], dtype=int32),\n",
       "  'outputs': array([7], dtype=int32)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter._get_ops_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idx = 5\n",
    "bias_idx = 2\n",
    "weight_idx = 3\n",
    "output_idx = 6\n",
    "\n",
    "w = interpreter.get_tensor(weight_idx)\n",
    "b = interpreter.get_tensor(bias_idx)\n",
    "q_i = interpreter.get_tensor_details()[input_idx][\"quantization\"]\n",
    "q_w = interpreter.get_tensor_details()[weight_idx][\"quantization\"]\n",
    "q_o = interpreter.get_tensor_details()[output_idx][\"quantization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) flatten input\n",
    "flattened_input = input_tensor.reshape(interpreter.get_tensor(1)) # [-1, 784]\n",
    "\n",
    "# 2) shift input tensor by -128 to sitch from input type (uint8) to TF Lite internal type (int8) \n",
    "finalised_input = flattened_input.astype(np.int32)\n",
    "finalised_input = finalised_input - 128\n",
    "finalised_input = finalised_input.astype(np.int8)\n",
    "\n",
    "# 3) run fully-connected layer\n",
    "fc1 = fc_and_requantize(finalised_input, w, b, q_i, q_w, q_o)\n",
    "\n",
    "# 4) undo the shift to switch from TF Lite internal type (int8) to output type (uint8)\n",
    "manual_output = fc1.astype(np.int32)\n",
    "manual_output = manual_output + 128\n",
    "manual_output = manual_output.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(manual_output == tflite_output).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly more optimised version of the simple model (TF Lite and manual) to meaningfully compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_S, I_Z = input_details[\"quantization\"]\n",
    "RESHAPE = interpreter.get_tensor(1)\n",
    "\n",
    "W_32 = interpreter.get_tensor(3).transpose().astype(np.int32)\n",
    "B_32 = interpreter.get_tensor(2).astype(np.int32)\n",
    "(S_I, Z_I) = interpreter.get_tensor_details()[5][\"quantization\"]\n",
    "(S_W, Z_W) = interpreter.get_tensor_details()[3][\"quantization\"]\n",
    "(S_O, Z_O) = interpreter.get_tensor_details()[6][\"quantization\"]\n",
    "S = S_I * S_W / S_O\n",
    "\n",
    "def quantise_input(x):\n",
    "    x_q = quantize_nearest(x, I_S, I_Z, np.uint8)\n",
    "    return np.expand_dims(x_q, axis=0)\n",
    "\n",
    "def manual_model(x):\n",
    "    x = (x.reshape(RESHAPE).astype(np.int32) - 128).astype(np.int8)\n",
    "    x = x.astype(np.int32) - Z_I\n",
    "    x = np.matmul(x, W_32) + B_32\n",
    "    x = np.clip(np.rint(S * x) + Z_O, -128, 127)\n",
    "    x = (x + 128).astype(np.uint8)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "quantised_test_x = [quantise_input(x) for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2 ms ± 83.9 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for x in quantised_test_x:\n",
    "    interpreter.set_tensor(input_details[\"index\"], x)\n",
    "    interpreter.invoke()\n",
    "    interpreter.get_tensor(output_details[\"index\"])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 ms ± 197 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for x in quantised_test_x:\n",
    "    manual_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple results\n",
    "\n",
    "- The cumulative execution time of the TF Lite model on the 10000 test images is ~18 ms (average over several runs)\n",
    "- The cumulative execution time of the manual model on the 10000 test images is ~116 ms (idem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancies = []\n",
    "\n",
    "for (i, x) in enumerate(quantised_test_x):\n",
    "\n",
    "    # TF Lite model\n",
    "    interpreter.set_tensor(input_details[\"index\"], x)\n",
    "    interpreter.invoke()\n",
    "    tflite_output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    # Manual model\n",
    "    manual_output = manual_model(x)\n",
    "\n",
    "    if not (tflite_output == manual_output).all():\n",
    "        discrepancies.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discrepancies)/len(quantised_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[\"index\"], ip)\n",
    "interpreter.invoke()\n",
    "outl = interpreter.get_tensor(output_details[\"index\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_m = manual_model(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outl == out_m).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(out_m, outl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic = 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = quantised_test_x[problematic]\n",
    "\n",
    "interpreter.set_tensor(input_details[\"index\"], x)\n",
    "interpreter.invoke()\n",
    "tflite_output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "manual_output = manual_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144 156 185 150 149 159 153 173 163 173]\n",
      "[[144 156 185 150 149 159 153 173 162 173]]\n"
     ]
    }
   ],
   "source": [
    "print(tflite_output)\n",
    "print(manual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = (x.reshape(RESHAPE).astype(np.int32) - 128).astype(np.int8)\n",
    "x2 = x1.astype(np.int32) - Z_I\n",
    "x3 = np.matmul(x2, W_32) + B_32\n",
    "x4 = np.clip(np.rint(S * x3).astype(np.int32) + Z_O, -128, 127)\n",
    "x5 = (x4 + 128).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1 == interpreter.get_tensor(5)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 28, 57, 22, 21, 31, 25, 45, 35, 45]], dtype=int8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 28, 57, 22, 21, 31, 25, 45, 34, 45]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rint(S * x3).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_round: np.vectorize(lambda x: np.floor(x + np.copysign(0.5, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUNDING_PRECISION = 32\n",
    "\n",
    "# TODO perhaps this can be done slightly more elegantly assuming S > 0\n",
    "# negative S, aside from theoretically never happening, would break our rounding assumption below\n",
    "if S < 0:\n",
    "    raise Exception(\"S must be positive\")\n",
    "\n",
    "scaled_m = 2**ROUNDING_PRECISION * S\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(S)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
