{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from math import log2, ceil, floor\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(HOME_DIR, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_nearest(x, scale, zero, qtype):\n",
    "    if qtype not in {np.int8, np.uint8}:\n",
    "        raise Exception(\"Only quantization to int8 or uint8 is supported\")\n",
    "    \n",
    "    (min, max) = (-128, 127) if qtype == np.int8 else (0, 255)\n",
    "\n",
    "    return np.clip(np.rint(x / scale) + zero, min, max).astype(qtype)\n",
    "\n",
    "def fc_and_requantize(input_tensor, weights, bias, q_i, q_w, q_o):\n",
    "    \n",
    "    if input_tensor.dtype != np.int8:\n",
    "        raise Exception(\"Input must be of type int8\")\n",
    "    \n",
    "    if weights.dtype != np.int8:\n",
    "        raise Exception(\"Weights must be of type int8\")\n",
    "    \n",
    "    if bias.dtype != np.int32:\n",
    "        raise Exception(\"Input and weights must be of type int32\")\n",
    "    \n",
    "    (s_i, z_i), (s_w, z_w), (s_o, z_o) = q_i, q_w, q_o\n",
    "    \n",
    "    if z_w != 0:\n",
    "        raise Exception(\"Expected zero point of weights to be 0\")\n",
    "\n",
    "    s = s_i * s_w / s_o\n",
    "\n",
    "    # 1) shift input tensor\n",
    "    input_tensor_32 = input_tensor.astype(np.int32) - z_i\n",
    "    weights_32 = weights.astype(np.int32)\n",
    "\n",
    "    # 2) compute the bmm\n",
    "    bmm = np.matmul(input_tensor_32, weights_32.transpose()) + bias\n",
    "\n",
    "    # 3) requantize\n",
    "    rq = np.rint(s * bmm) + z_o\n",
    "\n",
    "    # 4) saturating cast\n",
    "    output = np.clip(rq, -128, 127).astype(np.int8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255.0, x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(os.path.join(MODEL_DIR, \"simple_model_quant.tflite\"), experimental_preserve_all_tensors=True)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'serving_default_flatten_2_input:0', 'index': 0, 'shape': array([ 1, 28, 28], dtype=int32), 'shape_signature': array([-1, 28, 28], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003921568859368563, 0), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "<class 'numpy.uint8'>\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 7, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.1573459506034851, 175), 'quantization_parameters': {'scales': array([0.15734595], dtype=float32), 'zero_points': array([175], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "<class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "print(input_details)\n",
    "print(input_details[\"dtype\"])\n",
    "\n",
    "print(output_details)\n",
    "print(output_details[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_flatten_2_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 28, 28], dtype=int32),\n",
       "  'shape_signature': array([-1, 28, 28], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.003921568859368563, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/flatten_2/Const',\n",
       "  'index': 1,\n",
       "  'shape': array([2], dtype=int32),\n",
       "  'shape_signature': array([2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/dense_2/BiasAdd/ReadVariableOp',\n",
       "  'index': 2,\n",
       "  'shape': array([10], dtype=int32),\n",
       "  'shape_signature': array([10], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (4.8770318244351074e-05, 0),\n",
       "  'quantization_parameters': {'scales': array([4.877032e-05], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/dense_2/MatMul',\n",
       "  'index': 3,\n",
       "  'shape': array([ 10, 784], dtype=int32),\n",
       "  'shape_signature': array([ 10, 784], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.012436429969966412, 0),\n",
       "  'quantization_parameters': {'scales': array([0.01243643], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'tfl.quantize',\n",
       "  'index': 4,\n",
       "  'shape': array([ 1, 28, 28], dtype=int32),\n",
       "  'shape_signature': array([-1, 28, 28], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_3/flatten_2/Reshape',\n",
       "  'index': 5,\n",
       "  'shape': array([  1, 784], dtype=int32),\n",
       "  'shape_signature': array([ -1, 784], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'StatefulPartitionedCall:01',\n",
       "  'index': 6,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([-1, 10], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.1573459506034851, 47),\n",
       "  'quantization_parameters': {'scales': array([0.15734595], dtype=float32),\n",
       "   'zero_points': array([47], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 7,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([-1, 10], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.1573459506034851, 175),\n",
       "  'quantization_parameters': {'scales': array([0.15734595], dtype=float32),\n",
       "   'zero_points': array([175], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: serving_default_flatten_2_input:0\n",
      "1: sequential_3/flatten_2/Const\n",
      "2: sequential_3/dense_2/BiasAdd/ReadVariableOp\n",
      "3: sequential_3/dense_2/MatMul\n",
      "4: tfl.quantize\n",
      "5: sequential_3/flatten_2/Reshape\n",
      "6: StatefulPartitionedCall:01\n",
      "7: StatefulPartitionedCall:0\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(interpreter.get_tensor_details()):\n",
    "    print(i, \": \", t[\"name\"], sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'op_name': 'QUANTIZE',\n",
       "  'inputs': array([0], dtype=int32),\n",
       "  'outputs': array([4], dtype=int32)},\n",
       " {'index': 1,\n",
       "  'op_name': 'RESHAPE',\n",
       "  'inputs': array([4, 1], dtype=int32),\n",
       "  'outputs': array([5], dtype=int32)},\n",
       " {'index': 2,\n",
       "  'op_name': 'FULLY_CONNECTED',\n",
       "  'inputs': array([5, 3, 2], dtype=int32),\n",
       "  'outputs': array([6], dtype=int32)},\n",
       " {'index': 3,\n",
       "  'op_name': 'QUANTIZE',\n",
       "  'inputs': array([6], dtype=int32),\n",
       "  'outputs': array([7], dtype=int32)}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter._get_ops_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idx = 5\n",
    "bias_idx = 2\n",
    "weight_idx = 3\n",
    "output_idx = 6\n",
    "\n",
    "w = interpreter.get_tensor(weight_idx)\n",
    "b = interpreter.get_tensor(bias_idx)\n",
    "q_i = interpreter.get_tensor_details()[input_idx][\"quantization\"]\n",
    "q_w = interpreter.get_tensor_details()[weight_idx][\"quantization\"]\n",
    "q_o = interpreter.get_tensor_details()[output_idx][\"quantization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_model(input_tensor):\n",
    "\n",
    "    # 1) shift input tensor by -128 to sitch from input type (uint8) to TF Lite internal type (int8) \n",
    "    shifted_input = input_tensor.astype(np.int32)\n",
    "    shifted_input = shifted_input - 128\n",
    "    shifted_input = shifted_input.astype(np.int8)\n",
    "\n",
    "    # 2) flatten input\n",
    "    flattened_input = shifted_input.reshape(interpreter.get_tensor(1)) # [-1, 784]\n",
    "\n",
    "    # 3) run fully-connected layer\n",
    "    fc1 = fc_and_requantize(flattened_input, w, b, q_i, q_w, q_o)\n",
    "\n",
    "    # 4) undo the shift to switch from TF Lite internal type (int8) to output type (uint8)\n",
    "    output = fc1.astype(np.int32)\n",
    "    output = output + 128\n",
    "    output = output.astype(np.uint8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_image = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image 150\n",
      "TF Lite output:\t\t[135 109 152 161 187 157 159 151 173 202]\n",
      "Manual model output:\t[135 109 152 161 187 157 159 151 173 202]\n",
      "Correct label: 9\n"
     ]
    }
   ],
   "source": [
    "test_image = x_test[chosen_image]\n",
    "\n",
    "# Need to quantize the inputs outside the model!\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "input_tensor = quantize_nearest(test_image, input_scale, input_zero_point, np.uint8)\n",
    "input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "# Run the TF Lite model\n",
    "interpreter.set_tensor(input_details[\"index\"], input_tensor)\n",
    "interpreter.invoke()\n",
    "tflite_output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "# Run the manual model\n",
    "manual_output = manual_model(input_tensor)[0]\n",
    "\n",
    "print(\"Test image {}\\nTF Lite output:\\t\\t{}\\nManual model output:\\t{}\\nCorrect label: {}\".format(chosen_image, tflite_output, manual_output, y_test[chosen_image]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(manual_output == tflite_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.003921569, 0.07058824 , 0.50980395 ,\n",
       "        0.7372549  , 0.7137255  , 0.30980393 , 0.003921569, 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.18039216 , 0.67058825 , 0.99607843 , 0.99607843 ,\n",
       "        0.99607843 , 0.99607843 , 0.99607843 , 0.5568628  , 0.003921569,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.33333334 , 0.9372549  , 0.99215686 , 0.7882353  , 0.61960787 ,\n",
       "        0.6862745  , 0.99215686 , 0.99607843 , 0.9843137  , 0.078431375,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.44313726 ,\n",
       "        0.9372549  , 0.9019608  , 0.40784314 , 0.         , 0.         ,\n",
       "        0.         , 0.41960785 , 0.91764706 , 0.40392157 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.0627451  , 0.85490197 ,\n",
       "        0.9490196  , 0.1254902  , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.08627451 , 0.08627451 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.007843138, 0.68235296 , 0.99607843 ,\n",
       "        0.6        , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.05882353 , 0.40392157 ,\n",
       "        0.02745098 , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.2509804  , 0.99607843 , 0.91764706 ,\n",
       "        0.12941177 , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.14117648 , 0.87058824 , 0.99607843 ,\n",
       "        0.31764707 , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.72156864 , 0.99607843 , 0.5254902  ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.03137255 , 0.83137256 , 0.99607843 , 0.99607843 ,\n",
       "        0.24313726 , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.72156864 , 0.99607843 , 0.4509804  ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.12941177 , 0.7607843  , 0.99607843 , 0.99607843 , 0.99607843 ,\n",
       "        0.0627451  , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.6666667  , 0.99607843 , 0.98039216 ,\n",
       "        0.42352942 , 0.16470589 , 0.16470589 , 0.16470589 , 0.60784316 ,\n",
       "        0.972549   , 0.99607843 , 0.99607843 , 0.99607843 , 0.4627451  ,\n",
       "        0.011764706, 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.08627451 , 0.8666667  , 0.99607843 ,\n",
       "        0.99607843 , 0.99607843 , 0.99607843 , 0.99607843 , 0.99607843 ,\n",
       "        0.8392157  , 0.654902   , 0.99607843 , 0.99607843 , 0.29803923 ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.10980392 , 0.7254902  ,\n",
       "        0.99607843 , 0.99607843 , 0.74509805 , 0.90588236 , 0.77254903 ,\n",
       "        0.11764706 , 0.7137255  , 0.99607843 , 0.99607843 , 0.08235294 ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.05490196 ,\n",
       "        0.27450982 , 0.30588236 , 0.07058824 , 0.105882354, 0.023529412,\n",
       "        0.         , 0.87058824 , 0.99607843 , 0.78431374 , 0.011764706,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.87058824 , 0.99607843 , 0.4627451  , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.050980393, 0.9019608  , 0.99607843 , 0.5294118  , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.28627452 , 0.99607843 , 0.99607843 , 0.42745098 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.5254902  , 1.         , 0.99607843 , 0.42745098 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.5254902  , 0.99607843 , 0.99607843 , 0.42745098 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.5254902  , 0.99607843 , 0.99607843 , 0.42745098 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.5254902  , 0.99607843 , 0.99607843 , 0.21176471 , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ],\n",
       "       [0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         , 0.         , 0.         ,\n",
       "        0.         , 0.         , 0.         ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.set_printoptions(precision=30, suppress=True)\n",
    "# x_test[chosen_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec![\n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003921569, 0.07058824, 0.50980395, 0.7372549, 0.7137255, 0.30980393, 0.003921569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18039216, 0.67058825, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.5568628, 0.003921569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333334, 0.9372549, 0.99215686, 0.7882353, 0.61960787, 0.6862745, 0.99215686, 0.99607843, 0.9843137, 0.078431375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44313726, 0.9372549, 0.9019608, 0.40784314, 0.0, 0.0, 0.0, 0.41960785, 0.91764706, 0.40392157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0627451, 0.85490197, 0.9490196, 0.1254902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451, 0.08627451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007843138, 0.68235296, 0.99607843, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05882353, 0.40392157, 0.02745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2509804, 0.99607843, 0.91764706, 0.12941177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14117648, 0.87058824, 0.99607843, 0.31764707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72156864, 0.99607843, 0.5254902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03137255, 0.83137256, 0.99607843, 0.99607843, 0.24313726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72156864, 0.99607843, 0.4509804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12941177, 0.7607843, 0.99607843, 0.99607843, 0.99607843, 0.0627451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666667, 0.99607843, 0.98039216, 0.42352942, 0.16470589, 0.16470589, 0.16470589, 0.60784316, 0.972549, 0.99607843, 0.99607843, 0.99607843, 0.4627451, 0.011764706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451, 0.8666667, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.8392157, 0.654902, 0.99607843, 0.99607843, 0.29803923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10980392, 0.7254902, 0.99607843, 0.99607843, 0.74509805, 0.90588236, 0.77254903, 0.11764706, 0.7137255, 0.99607843, 0.99607843, 0.08235294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05490196, 0.27450982, 0.30588236, 0.07058824, 0.105882354, 0.023529412, 0.0, 0.87058824, 0.99607843, 0.78431374, 0.011764706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.87058824, 0.99607843, 0.4627451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050980393, 0.9019608, 0.99607843, 0.5294118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28627452, 0.99607843, 0.99607843, 0.42745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5254902, 1.0, 0.99607843, 0.42745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5254902, 0.99607843, 0.99607843, 0.42745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5254902, 0.99607843, 0.99607843, 0.42745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5254902, 0.99607843, 0.99607843, 0.21176471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "    vec!0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"vec![\")\n",
    "\n",
    "for sa in x_test[chosen_image]:\n",
    "    print(\"    vec!{}, \".format(\", \".join([str(e) for e in sa])))\n",
    "\n",
    "print(\"]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
